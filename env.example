# BookSpine Environment Configuration
# Copy this file to .env and fill in your values

# Hugging Face API Token (Optional)
# Get a free token at: https://huggingface.co/settings/tokens
# This helps avoid rate limiting when downloading models
HF_TOKEN=your_huggingface_token_here

# Hugging Face Cache Directory (Optional)
# Default: ~/.cache/huggingface
HF_HOME=~/.cache/huggingface

# Disable Hugging Face Telemetry (Recommended)
HF_HUB_DISABLE_TELEMETRY=1

# Disable Implicit Token (Recommended)
HF_HUB_DISABLE_IMPLICIT_TOKEN=1

KTE_MODEL_NAME=sentence-transformers/all-MiniLM-L6-v2
# valid options: hf, local, stapi, infinity (https://github.com/michaelfeil/infinity)
KTE_ENGINE=hf
KTE_AUTH_TOKEN=
KTE_API_URL=https://router.huggingface.co/hf-inference/models/sentence-transformers/all-MiniLM-L6-v2/pipeline/sentence-similarity
